{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "673e797a-e31c-4e33-8b96-5bdf121f386e",
   "metadata": {},
   "source": [
    "# Deep Learning: CNN with ASL dataset\n",
    "> AHSNCCU/NTNU CSIE 王修佑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182fcb09-83df-438e-ae32-319bef55a646",
   "metadata": {},
   "source": [
    "Convolution Neural Network 卷積神經網路"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f3e84c-80ae-4c70-9383-33bf28312a44",
   "metadata": {},
   "source": [
    "## 載入和準備資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fec1e9-e332-41b1-8cc3-f0ee2ac4bebc",
   "metadata": {},
   "source": [
    "> Colab要先 `!git clone https://github.com/whyhugo/CV-handouts.git`  \n",
    "> 檔案位置修改為 `\"/content/CV-handouts/asl/FileName\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529edd19-f8cb-4f41-bd83-63a3a7342c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "\n",
    "# Load in our data from CSV files\n",
    "train_df = pd.read_csv(\"asl/sign_mnist_train.csv\")\n",
    "valid_df = pd.read_csv(\"asl/sign_mnist_valid.csv\")\n",
    "\n",
    "# Separate out our target values\n",
    "y_train = train_df['label']\n",
    "y_valid = valid_df['label']\n",
    "del train_df['label']\n",
    "del valid_df['label']\n",
    "\n",
    "# Separate out our image vectors\n",
    "x_train = train_df.values\n",
    "x_valid = valid_df.values\n",
    "\n",
    "# Turn our scalar targets into binary categories\n",
    "num_classes = 24\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
    "\n",
    "# Normalize our image data\n",
    "x_train = x_train / 255\n",
    "x_valid = x_valid / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0171652-face-4fb8-970f-3a9b9329cf85",
   "metadata": {},
   "source": [
    "## 為卷積神經網路重新調整影像"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de28c9af-63b8-4d59-851c-dbafa4e600d2",
   "metadata": {},
   "source": [
    "+ 將目前的形狀(784像素) `(27455, 784)`轉換成(28x28像素) `(27455, 28, 28, 1)`\n",
    "+ reshape(`-1`不改變維度, `28`像素, `28`像素, `1`色頻數量)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb0f7aa-1cbe-4be3-8efa-a0cad353639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ac365-ede4-48a2-a287-3cbee7efead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_valid = x_valid.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22038c21-d4b7-4ff1-9614-d9310ad58334",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c57c9-1151-4bdd-9cc9-32c82bcc230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ff4cce-0d69-4696-b5bf-e48f83cee3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9afb05e-bfa7-4396-ab14-1b7da8d2e467",
   "metadata": {},
   "source": [
    "## 建立卷積模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4391f5-4394-41d5-b079-1fafa761934c",
   "metadata": {},
   "source": [
    "<img src=\"images/cnn.png\" width=180 />\n",
    "\n",
    "解決類似的問題，可使用開源模型修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6177b7-94db-4dad-99ac-1d22fa1d34c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(75, (3, 3), strides=1, padding=\"same\", activation=\"relu\", \n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "model.add(Conv2D(50, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "model.add(Conv2D(25, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc2eb03-3d18-412e-9f70-39b7e99e281e",
   "metadata": {},
   "source": [
    "### Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accf6c6b-e3e8-442a-ad7f-4c7f47e5aced",
   "metadata": {},
   "source": [
    "<img src=\"images/conv2d.png\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e432d802-fbfa-4799-bca9-bb6da1445213",
   "metadata": {},
   "source": [
    "2D 卷積層\n",
    "```Python\n",
    "model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same'...)\n",
    "```\n",
    "75 指的是將要學習的核心(過濾器filter)數量。(3,3) 指的是這些核心的大小。strides指的是濾鏡經過影像時採用的步長。padding指的是從濾鏡建立的輸出影像是否與輸入影像的大小相符(convolution 會縮小)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1782373f-a475-4dbd-ae97-a5122d20d554",
   "metadata": {},
   "source": [
    "<img src=\"images/filter.gif\" width=600 />\n",
    "\n",
    "> ☝️這就是權重共享\n",
    "\n",
    "> Feature Map Size: Output = (Input+2Padding-FilterSize)/Stride+1 = Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db47301-3bcf-4f72-a930-77e37d14e71e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d14df1-9600-4258-949c-9c73ed3e6970",
   "metadata": {},
   "source": [
    "批次正規化\n",
    "> 調整隱藏層中的值，以提升訓練品質<br>\n",
    "+ 有效減緩Activation Function(Sigmoid) 梯度(Gradient)消失的問題\n",
    "+ 解決 Internal Covariate Shift\n",
    "+ 加速模型收斂\n",
    "+ 具有正則化效果\n",
    "\n",
    "> Reference: https://medium.com/ching-i/batch-normalization-%E4%BB%8B%E7%B4%B9-135a24928f12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb33d354-8a5b-4c43-b401-af61e5ebebb0",
   "metadata": {},
   "source": [
    "### MaxPool2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab4e19-f400-4fad-95bb-3b231ac8c40c",
   "metadata": {},
   "source": [
    "池化方式比較\n",
    "\n",
    "<img src=\"images/池化方式比較.png\" width=350 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5851df-0308-44d5-9506-517f71cb4cab",
   "metadata": {},
   "source": [
    "+ 藉由對資料subsampling，減少計算成本\n",
    "+ 同時可保有特徵不變性\n",
    "+ 總結來講，提高Receptive Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0510e8c-6662-48ab-940a-58c99981b5a3",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185fd186-e08b-42e0-b099-5b754d6a0bd0",
   "metadata": {},
   "source": [
    "+ 預防Overfitting\n",
    "+ 原理：隨機選取並關閉神經元的子集，所以這些神經元不會在特定階段中參與正向或反向傳播。這有助於確保網路的泛化和降低冗餘神經元發生機率，且不依賴任何單一區域來產生答案。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669771ce-5e4f-41f0-990d-ff6c84a3f3b6",
   "metadata": {},
   "source": [
    "### Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb6761-d9ec-4059-85bb-885045f4d788",
   "metadata": {},
   "source": [
    "為進入下一層FC做準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fffe644-0cf9-46bf-abe6-cb9d620df52a",
   "metadata": {},
   "source": [
    "### Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea15738a-ff79-480f-b3f3-549a9c7934f1",
   "metadata": {},
   "source": [
    "運用Activation Function分類！👉輸出預測結果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990dd459-ff1c-4c9b-adf4-0d39d65f7a55",
   "metadata": {},
   "source": [
    "## 總結模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8588bad-3f1c-4b0f-af49-b9b3363f7bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b943eb1-9b3b-42ae-856d-96ac4753968d",
   "metadata": {},
   "source": [
    "## 編寫模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a52ca9-51d4-4ba5-81c0-302c4ea81381",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc66c0c-a051-400d-9be4-b1fc0c80aa0a",
   "metadata": {},
   "source": [
    "## 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df557519-dc92-4cc0-a0bc-1c9455281b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=20, verbose=1, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e321a5-e072-4409-b666-b77fb2915c90",
   "metadata": {},
   "source": [
    "## 結果討論"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454cae65-622c-41e2-a2f8-de055c5436c1",
   "metadata": {},
   "source": [
    "訓練準確度與驗證準確度是否都提高了呢？  \n",
    "model仍沒有完美泛化(Generalization)的能力？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd68d99-f2e6-4730-a41d-4c621a59f609",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 清除記憶體"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e3c889-f202-4926-8d2f-0488edf5aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
