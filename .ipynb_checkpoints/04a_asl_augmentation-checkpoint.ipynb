{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning: Data Augmentation with ASL dataset\n",
    "> AHSNCCU/NTNU CSIE 王修佑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料增強<br>\n",
    "+ 增加資料集的大小和變異數\n",
    "+ 選出對分類有用的特徵，讓模型具備更出色的歸納能力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/資料增強.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "\n",
    "# Load in our data from CSV files\n",
    "train_df = pd.read_csv(\"asl/sign_mnist_train.csv\")\n",
    "valid_df = pd.read_csv(\"asl/sign_mnist_valid.csv\")\n",
    "\n",
    "# Separate out our target values\n",
    "y_train = train_df['label']\n",
    "y_valid = valid_df['label']\n",
    "del train_df['label']\n",
    "del valid_df['label']\n",
    "\n",
    "# Separate our our image vectors\n",
    "x_train = train_df.values\n",
    "x_valid = valid_df.values\n",
    "\n",
    "# Turn our scalar targets into binary categories\n",
    "num_classes = 24\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
    "\n",
    "# Normalize our image data\n",
    "x_train = x_train / 255\n",
    "x_valid = x_valid / 255\n",
    "\n",
    "# Reshape the image data for the convolutional network\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_valid = x_valid.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(75, (3, 3), strides=1, padding=\"same\", activation=\"relu\", \n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "model.add(Conv2D(50, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "model.add(Conv2D(25, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料增強"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "運用Keras `ImageDataGenerator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.1,  # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images horizontally\n",
    "    vertical_flip=False, # Don't randomly flip images vertically\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "為何我們要水平翻轉影像，而不是垂直翻轉？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 批次大小\n",
    "`ImageDataGenerator`批次處理我們的資料，讓模型能以隨機的樣本進行訓練。\n",
    "\n",
    "模型隨機採取資料中一小部分樣本，即可代表所有資料\n",
    "\n",
    "> 批次大小為 32 和 64 的效果比較理想"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "batch_size = 32\n",
    "img_iter = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "x, y = img_iter.next()\n",
    "fig, ax = plt.subplots(nrows=4, ncols=8)\n",
    "for i in range(batch_size):\n",
    "    image = x[i]\n",
    "    ax.flatten()[i].imshow(np.squeeze(image))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將資料擬合生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 編譯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 透過增強進行訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 傳遞 `x_train`、`y_train` 與 **生成器**到模型\n",
    "+ 生成器(Generator)生成增強影像\n",
    "+ 記得要設定Epoch時間\n",
    "+ Keras [Flow](https://keras.io/api/preprocessing/image/)方法\n",
    "\n",
    "`steps * batch_size = number_of_images_trained in an epoch`\n",
    "\n",
    "執行下列儲存格以查看結果。訓練時間比先前更長，畢竟我們現在比之前使用更多資料進行訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(img_iter,\n",
    "          epochs=20,\n",
    "          steps_per_epoch=len(x_train)/batch_size, # Run same number of steps we would if we were not using a generator.\n",
    "          validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果討論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "驗證正確率提升了~  \n",
    "解決了Overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 儲存模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 使用 save 方法將模型儲存在 Keras。\n",
    "> [說明文件](https://www.tensorflow.org/guide/keras/save_and_serialize)\n",
    "+ 各框架常用模型格式\n",
    "    + ONNX (.onnx, .pb, .pbtxt)\n",
    "    + Keras (.h5, .keras)\n",
    "    + Core ML (.mlmodel)\n",
    "    + Caffe2 (predict_net.pb, predict_net.pbtxt)\n",
    "    + MXNet (.model, -symbol.json) \n",
    "    + TensorFlow Lite (.tflite). \n",
    "    + Caffe (.caffemodel, .prototxt)\n",
    "    + PyTorch (.pt, .pth)\n",
    "    + TorchScript (.pt, .pth)\n",
    "    + Torch (.t7), CNTK (.model, .cntk)\n",
    "    + PaddlePaddle (__model__)\n",
    "    + Darknet (.cfg)\n",
    "    + NCNN (.param)\n",
    "    + scikit-learn (.pkl)\n",
    "    + TensorFlow.js (model.json, .pb)\n",
    "    + TensorFlow (.pb, .meta, .pbtxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('asl_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 清除記憶體"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
