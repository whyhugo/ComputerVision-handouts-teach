{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04538559-925a-498b-9b63-84b66e9e5a9c",
   "metadata": {},
   "source": [
    "# Deep Learning: Image Classification with ASL dataset\n",
    "> AHSNCCU/NTNU CSIE 王修佑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf9a2b1-2b89-42a4-9d04-a4dbef7cee74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 美國手語資料集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef72e2b-f3fa-4ad2-ad53-07516d847276",
   "metadata": {},
   "source": [
    "[美國手語字母表](http://www.asl.gs/)含有 26 個字母。其中兩個字母 (j 和 z) 需要移動，因此不會包含在訓練資料集中。\n",
    "\n",
    "<img src = \"./asl/american_sign_language.PNG\" style=\"width: 600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54836248-0272-4e04-9119-1ed8f8b09ed3",
   "metadata": {},
   "source": [
    "## 載入資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4025e3-09b2-4e5c-aa41-2d78a900bad0",
   "metadata": {},
   "source": [
    "> 我們資料集的取得方式👉Kaggle  \n",
    "> https://www.kaggle.com/datasets/datamunge/sign-language-mnist  \n",
    "> (社課中建議可直接從reps取得)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e409dc-740e-43a2-9cfc-9418a2a8b5c7",
   "metadata": {},
   "source": [
    "我們要將資料集化分為 `x_train`、`y_train`、`x_valid` 和 `y_valid` 變數"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cd0605-d4f5-4bc9-a233-b416a5fd6943",
   "metadata": {},
   "source": [
    "### 讀取資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fee0c4-3e91-4da9-b64a-ed432873f798",
   "metadata": {},
   "source": [
    "使用Pandas函式庫讀取CSV file，透過DataFrame處理資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ba62b-c622-42e1-9808-8c563e30f510",
   "metadata": {},
   "source": [
    "> Colab要先 `!git clone https://github.com/whyhugo/CV-handouts.git`  \n",
    "> 檔案位置修改為 `\"/content/CV-handouts/asl/FileName\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0a78d4-9445-4589-ac7c-c58ab98bbb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"asl/sign_mnist_train.csv\")\n",
    "valid_df = pd.read_csv(\"asl/sign_mnist_valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68a942f-cfa5-4be4-9ce3-d7cf98d2ce75",
   "metadata": {},
   "source": [
    "### 探索資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114dfda9-5ad4-44e2-9ba1-188f61c0fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f814737f-2087-4250-9bda-cd1a370d9418",
   "metadata": {},
   "source": [
    "### 擷取影像類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d64f91-94b0-487b-9196-4fe72e8fc2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['label']\n",
    "y_valid = valid_df['label']\n",
    "del train_df['label']\n",
    "del valid_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233b39a7-415e-49bb-a195-f54610bbac48",
   "metadata": {},
   "source": [
    "### 擷取影像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02588249-4742-40db-a926-ee243dec6442",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.values\n",
    "x_valid = valid_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9802da51-8071-4791-b1f3-6a6df9445330",
   "metadata": {},
   "source": [
    "### 總結訓練與驗證資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59de77d-6853-4d10-80c3-95b02dab1ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a2fed7-8dee-4f09-bfd8-e0e8421c2b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8551ac-8e6a-44f6-99d8-a795efed77fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e647297-b37c-4804-ab0b-035682c25bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ed6a96-535d-4ede-9111-dc83c3dd1944",
   "metadata": {},
   "source": [
    "## 視覺化資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d4857d-b204-4907-8458-f946a29f1958",
   "metadata": {},
   "source": [
    "把資料(image) 1D to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81affcfa-f0a2-411e-b660-651e4c3af51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(40,40))\n",
    "\n",
    "num_images = 20\n",
    "for i in range(num_images):\n",
    "    row = x_train[i]\n",
    "    label = y_train[i]\n",
    "    \n",
    "    image = row.reshape(28,28)\n",
    "    plt.subplot(1, num_images, i+1)\n",
    "    plt.title(label, fontdict={'fontsize': 30})\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc241772-6a77-435c-b8e3-fadf2fee330e",
   "metadata": {},
   "source": [
    "## 練習：正規化影像資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef7d75b-01aa-4a49-a0b5-3b51eb3e88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d298f011-d42c-4b23-8cf6-f7b8e82399ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2323fa4d-28e0-4c71-ab8b-47f5c8dcfdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalize x_train and x_valid.\n",
    "x_train = x_train / 255\n",
    "x_valid = x_valid / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48e5a68-4100-4029-ae97-fa74006939f2",
   "metadata": {},
   "source": [
    "## 練習：影像分類"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca580e60-3681-483b-9259-23e6698174ea",
   "metadata": {},
   "source": [
    "Hint: 使用 [keras.utils.to_categorical](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab181c64-04f8-45af-9a50-6673d66ed21b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "num_classes = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5ea8be-74ab-4114-b03d-1e9dd1568518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Categorically encode y_train and y_valid.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf37235-8ced-4c48-a0e3-14b38e54a64b",
   "metadata": {},
   "source": [
    "## 練習：建立模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50bf64b-a287-4446-9256-ed994559aeb5",
   "metadata": {},
   "source": [
    "We need...\n",
    "* 具有密集輸入層。這一層包含 512 個神經元，使用 `relu`激活函數，並接收形狀為 `(784,)` 的輸入影像。\n",
    "* 具有第二個密集輸入層，含有 512 個使用 `relu`激活函數的神經元\n",
    "* 具有密集輸出層，其神經元的數量與類別數量相等，並使用 `softmax`激活函數\n",
    "\n",
    "還不熟悉，參考一下mnist的範例吧~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec834c-edbf-4053-8a92-3c8fcc925efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea91cb9-68bf-4f96-8138-aeb2879c991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: build a model following the guidelines above.\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(units = 512, activation='relu'))\n",
    "model.add(Dense(units = num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f08022-8c17-4cfe-9a30-8efe26f0cdd6",
   "metadata": {},
   "source": [
    "## 總結模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a595bcb2-749e-4eda-adbd-5a6a680a89f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6152e2-0bd3-4a8b-87bf-4694a6d3eefa",
   "metadata": {},
   "source": [
    "## 編寫模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abf7fb3-52a3-4555-956d-0bd6a909d6f1",
   "metadata": {},
   "source": [
    "使用[CategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a8632-a6d1-4545-8322-979903541fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e233c51-f8cb-4cfa-b24f-2588a60b87fe",
   "metadata": {},
   "source": [
    "## 練習：訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587b1ac0-cdbf-4d64-9969-8409e231526e",
   "metadata": {},
   "source": [
    "使用模型的 `fit`方法來對模型進行 20 個 Epoch 的訓練，使用的是先前建立的訓練與驗證影像和類別："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43d01a-4904-4909-93de-c35e69901f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train the model for 20 epochs.\n",
    "model.fit(x_train, y_train, epochs=20, verbose=1, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e604b7e-dbd7-4adb-9fe6-b6796dfefa6b",
   "metadata": {},
   "source": [
    "## 討論：發生什麼事了？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e0c49-4846-4139-992d-397d0ae8a229",
   "metadata": {
    "tags": []
   },
   "source": [
    "Overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d09155-3566-4b13-a6b2-fd1a32c5f3ae",
   "metadata": {},
   "source": [
    "## 清除記憶體"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ebbef9-1a8c-4bee-8dad-42ea521249a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
